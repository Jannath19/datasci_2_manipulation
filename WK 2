{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiUwYYjWmF/VAeFlalqhE+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jannath19/datasci_2_manipulation/blob/main/WK%202\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0lj1T_gSs8P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from the raw URL\n",
        "url = 'https://raw.githubusercontent.com/hantswilliams/HHA_507_2023/main/WK2/data/healthcare_data_cleaning.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Handle missing values (e.g., drop rows with missing values)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Remove duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Remove duplicate columns (if any)\n",
        "df = df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "# Clean column names\n",
        "df.columns = df.columns.str.strip().str.lower()\n"
      ],
      "metadata": {
        "id": "OWA8pWArU1QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning\n",
        "\n",
        "In this section, I performed data cleaning on the healthcare dataset:\n",
        "\n",
        "- I load the dataset using Pandas.\n",
        "- I identify and handle missing values by dropping rows with missing data.\n",
        "- I remove duplicate rows and columns from the dataset.\n",
        "- I clean the column names by stripping spaces and converting them to lowercase.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d0PidZ9EVn7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first few rows of your DataFrame to inspect column names\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2sc8bLXWnhd",
        "outputId": "e5ad355b-71cc-4c19-ff8a-61c91643cca3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  patient age  gender  city of residence state of residence has insurance  \\\n",
            "0          45   Other         West Brian           Kentucky           Yes   \n",
            "1          25  Female   East Jocelynfurt           Colorado            No   \n",
            "2          51   Other  South Lindseyland               Ohio           Yes   \n",
            "3          18  Female         Taylorfort       Pennsylvania           Yes   \n",
            "4          48  Female          Birdmouth            Montana            No   \n",
            "\n",
            "  visited last month payment method preferred doctor disease diagnosed  \\\n",
            "0                Yes      Insurance     Dr. Williams               Flu   \n",
            "1                Yes           Card      Dr. Johnson               Flu   \n",
            "2                 No           Cash     Dr. Williams          Covid-19   \n",
            "3            missing           Cash     Dr. Williams               Flu   \n",
            "4                 No      Insurance        Dr. Brown              None   \n",
            "\n",
            "  medication prescribed type of appointment average heart rate average bp  \\\n",
            "0                 Med_E             General                 66        111   \n",
            "1                 Med_B          Specialist                 59    missing   \n",
            "2                 Med_D             General                 79        119   \n",
            "3                 Med_A             General                 99        115   \n",
            "4                 Med_C          Specialist                 93         89   \n",
            "\n",
            "  height (in cm) weight (in kg)     payment due ($) last visit (days ago)  \\\n",
            "0            183             70   65.45721578126224                   193   \n",
            "1            174             58  430.68365678679174                   195   \n",
            "2            161             56   315.0709305262176               missing   \n",
            "3            171             52   320.2998987723972                   175   \n",
            "4            186             87   264.2147372473319                   188   \n",
            "\n",
            "  visit duration (mins) number of tests prescription cost ($)  \n",
            "0                    92               5     15.71751735532889  \n",
            "1               missing               4     80.78647284463952  \n",
            "2                    37               2      64.3921393009105  \n",
            "3                   108               2     8.872859215315316  \n",
            "4                   113               3     77.48311304645532  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data Cleaning with Pandas\n",
        "# Load the dataset from the raw URL\n",
        "url = 'https://raw.githubusercontent.com/hantswilliams/HHA_507_2023/main/WK2/data/healthcare_data_cleaning.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Handle missing values (e.g., drop rows with missing values)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Remove duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Remove duplicate columns (if any)\n",
        "df = df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "# Clean column names\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# Clean the 'patient age' column by replacing 'missing' values with NaN\n",
        "df['patient age'] = pd.to_numeric(df['patient age'], errors='coerce')\n",
        "\n",
        "# Now, the data is cleaned and you can proceed with data transformation in Step 2.\n"
      ],
      "metadata": {
        "id": "O_TAPpbNZAxz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom age groups based on 'patient age'\n",
        "bins = [0, 18, 30, 40, 50, 60, 70, float('inf')]\n",
        "labels = ['0-17', '18-29', '30-39', '40-49', '50-59', '60-69', '70+']\n",
        "\n",
        "# Create a new column 'age_group' based on 'patient age'\n",
        "df['age_group'] = pd.cut(df['patient age'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Step 5: Create new columns based on existing ones\n",
        "# Calculate age from 'patient age' column (assuming 'patient age' is in years)\n",
        "df['age'] = df['patient age']\n",
        "\n",
        "# Step 6: Clean 'visit duration (mins)' column and convert to numeric\n",
        "df['visit duration (mins)'] = pd.to_numeric(df['visit duration (mins)'], errors='coerce')\n",
        "\n",
        "# Step 7: Aggregate data and compute summary statistics\n",
        "# Calculate average visit duration by gender and age group\n",
        "pivot_table = df.pivot_table(values='visit duration (mins)', index='gender', columns='age_group', aggfunc='mean')\n",
        "\n",
        "# Now you can proceed with data transformation and analysis using the 'age' column and 'visit duration (mins)'.\n"
      ],
      "metadata": {
        "id": "M1joHUpXZLrn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Data Transformation\n",
        "\n",
        "In this step, I performed various data transformations on the healthcare dataset to prepare it for analysis. Below are the details of the transformations:\n",
        "\n",
        "### 1. Creating Custom Age Groups\n",
        "To analyze age-related trends, I created custom age groups based on the 'patient age' column. Here are the age group categories:\n",
        "- 0-17\n",
        "- 18-29\n",
        "- 30-39\n",
        "- 40-49\n",
        "- 50-59\n",
        "- 60-69\n",
        "- 70+\n",
        "\n",
        "### 2. Calculating Age\n",
        "I calculated the 'age' of patients based on the 'patient age' column.\n",
        "\n",
        "### 3. Cleaning 'Visit Duration'\n",
        "I cleaned the 'visit duration (mins)' column by converting it to numeric data type.\n",
        "\n",
        "### 4. Aggregating Data\n",
        "- I calculated the average visit duration by gender.\n",
        "- I created a pivot table to analyze 'visit duration (mins)' by gender and age group. The pivot table allows for multi-dimensional analysis.\n"
      ],
      "metadata": {
        "id": "FDrIm8JjaW-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Polars library\n",
        "import polars as pl\n",
        "import time\n",
        "\n",
        "# Define the URL for your dataset\n",
        "url = 'https://raw.githubusercontent.com/hantswilliams/HHA_507_2023/main/WK2/data/healthcare_data_cleaning.csv'\n",
        "\n",
        "# Capture the start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Load the dataset using Polars\n",
        "df_polars = pl.read_csv(url)\n",
        "\n",
        "# Capture the end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the load time\n",
        "load_time_polars = end_time - start_time\n",
        "\n",
        "# Now, you have loaded the dataset using Polars, and you can compare the load times with Pandas.\n"
      ],
      "metadata": {
        "id": "2ZS5yegdakSS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k-gc6jUtabEQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}